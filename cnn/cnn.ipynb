{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.path.pardir, \"dataset\")\n",
    "assert os.path.exists(DATA_DIR)\n",
    "TRAINING_SET_SIZE = 400\n",
    "BATCH_SIZE = 10\n",
    "IMAGE_SIZE = 1536\n",
    "N_CHANNEL = 3\n",
    "N_CLASSES = 4\n",
    "FLAT_LEN = IMAGE_SIZE**2\n",
    "\n",
    "FEATURES_LIST = {\"image/encoded\": tf.FixedLenFeature([], tf.string),\n",
    "        \"image/height\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/width\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/filename\": tf.FixedLenFeature([], tf.string),\n",
    "        \"image/class/label\": tf.FixedLenFeature([], tf.int64),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "class _image_object:\n",
    "    def __init__(self):\n",
    "        self.image = tf.Variable([], dtype = tf.string)\n",
    "        self.height = tf.Variable([], dtype = tf.int64)\n",
    "        self.width = tf.Variable([], dtype = tf.int64)\n",
    "        self.filename = tf.Variable([], dtype = tf.string)\n",
    "        self.label = tf.Variable([], dtype = tf.int32)\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example, features=FEATURES_LIST)\n",
    "    image_encoded = features[\"image/encoded\"]\n",
    "    image_raw = tf.image.decode_jpeg(image_encoded, channels=N_CHANNEL)\n",
    "    image_object = _image_object()\n",
    "    image_object.image = tf.image.resize_image_with_crop_or_pad(image_raw, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    image_object.height = features[\"image/height\"]\n",
    "    image_object.width = features[\"image/width\"]\n",
    "    image_object.filename = features[\"image/filename\"]\n",
    "    image_object.label = tf.cast(features[\"image/class/label\"], tf.int64)\n",
    "    return image_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"benign_jpg\", \"insitu_jpg\", \"invasive_jpg\", \"normal_jpg\"]\n",
    "dataset_path = os.path.join(os.path.pardir, 'dataset')\n",
    "N_c = 100\n",
    "N = N_c*4\n",
    "size = 1536\n",
    "rgb_channel = 3\n",
    "\n",
    "dataset = np.ndarray([N, size, size, rgb_channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/benign_jpg/* ... loaded\n",
      "../dataset/insitu_jpg/* ... loaded\n",
      "../dataset/invasive_jpg/* ... loaded\n",
      "../dataset/normal_jpg/* ... loaded\n",
      "33.33758854866028\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "start_time = time.time()\n",
    "for i, class_name in enumerate(classes):\n",
    "    path = os.path.join(dataset_path, class_name)\n",
    "    files = os.listdir(path)\n",
    "    for j, img_name in enumerate(files):\n",
    "        if j < N_c:\n",
    "            im = Image.open(path + \"/\" + img_name)\n",
    "            imarray = np.array(im)\n",
    "            dataset[i*N_c + j] = imarray\n",
    "    print(path + \"/*\", \"... loaded\")\n",
    "end_time = time.time()\n",
    "run_time = end_time-start_time\n",
    "print(run_time)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart_time = time.time()\\nnp.save(\"dataset.npy\", dataset)\\nend_time = time.time()\\nrun_time = end_time-start_time\\nprint(run_time)\\n\\nstart_time = time.time()\\ndataset = np.load(\"dataset.npy\")\\nend_time = time.time()\\nrun_time = end_time-start_time\\nprint(run_time)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "start_time = time.time()\n",
    "np.save(\"dataset.npy\", dataset)\n",
    "end_time = time.time()\n",
    "run_time = end_time-start_time\n",
    "print(run_time)\n",
    "\n",
    "start_time = time.time()\n",
    "dataset = np.load(\"dataset.npy\")\n",
    "end_time = time.time()\n",
    "run_time = end_time-start_time\n",
    "print(run_time)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name =\n",
    "for i, class_name in enumerate(classes):\n",
    "    path = os.path.join(dataset_path, class_name)\n",
    "    files = os.listdir(path)\n",
    "    for j, img_name in enumerate(files):\n",
    "        if j < N_c:\n",
    "            im = Image.open(path + \"/\" + img_name)\n",
    "            imarray = np.array(im)\n",
    "            dataset[i*N_c + j] = imarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253 336 136 254 362 216 181 116 310  48  96 144 245 382 118 280 201 121\n",
      "  45 322 137 241 111 363 146 328 166 298   7 120 316 264  25 353 374  30\n",
      "  16 290 207 187 289 309  13 205 170 277 124  64 153  78 214 397 341 203\n",
      " 210 211   5  24 369 265 291 131  89  71 178 173 156 302 213 145  84  39\n",
      " 350 389 266  56 331 379   6 394 175  83  32 301 123 246 209  57 113 269\n",
      " 368 242 140 358 388 168 108  92  54  53 251 225 334 337 324  80 356 366\n",
      "  18 395 232 335 165 255  65 192 268 303  44 311 189 295 380 355 385 194\n",
      " 204  20 372 227 218 104 352   4 315 162   3 234 160 133 338 249 292  35\n",
      " 378  76 176  47  67 377 344 357 329 138 197 330 125 312 283 193  94 278\n",
      "  90 101 196 155 150 198  63 177 223 167 247 231  21 217 183  95  58 149\n",
      "  11 318 110 279 157  19 296 287  43 215  93  74 262 271 305 135 383 202\n",
      " 117 257 161 297 348 392  61 263  37 299 235 164 233  87 129 172 273 326\n",
      " 244 151 339 258 387 143 182  26 239 261 288 154 396  72 186 171  77  29\n",
      " 367   9 107  17 323   8 346  49  55 313 360 184  70 103 319  38 179 141\n",
      "  86 284 208  42   2  14 333 307 222 219 390  46  82  97 398 327  73 105\n",
      "  23 238 320 371 240  12 304 294  91 112 230  62  52  36 119   1 185 393\n",
      " 275 174 332 127  81 293  69  31 128 343 195 200  50 139 399 130 325 270\n",
      "  99 114 364 158 100 250 237 190  60 152 285 206 359 229 159 228 340 272\n",
      " 308 274   0 345 226  10 224 115 365 281 163 375 354 267 199 317 221 349\n",
      " 260 134 132  85 384 248 342 220 109  15 191 122 286  98 276 169 347 282\n",
      " 391 142 236 381  75 148 102  40  28 376  59 126 259 361 252  34  27 256\n",
      " 243 370  22 147 300  51  68 351 212 306 314 188  41 386  66 180  79 106\n",
      "  88  33 321 373]\n"
     ]
    }
   ],
   "source": [
    "#np.random.shuffle(dataset)\n",
    "index_permutation = np.array(range(N))\n",
    "np.random.shuffle(index_permutation)\n",
    "print(index_permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7a51128d7304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_permutation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_training\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvalidation_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_permutation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_training\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_validation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_permutation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_training\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_training\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_validation\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "n_training = int(.8 * N)\n",
    "n_validation = int(.1 * N)\n",
    "n_test = int(.1 * N)\n",
    "\n",
    "training_set = dataset[index_permutation[0:n_training]]\n",
    "validation_set = dataset[index_permutation[n_training:n_training+n_validation]]\n",
    "test_set = dataset[index_permutation[n_training+n_validation:n_training+n_validation+n_test]]\n",
    "\n",
    "print(training_set.shape)\n",
    "print(validation_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowCPU",
   "language": "python",
   "name": "tensorflowcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
